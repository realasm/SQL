!pip install -U scikit-learn

!pip install --upgrade pandas

import sklearn
import imblearn
!pip install --upgrade scikit-learn imbalanced-learn
print("scikit-learn version:", sklearn.__version__)

!pip install imbalanced-learn==0.8.0

import numpy as np
import pandas as pd
df=pd.read_csv('/content/drive/MyDrive/Datasets/Employee.csv')
df.head()

# * Models that are using in this dataset
# -------------------------------------------------------
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import BernoulliNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from xgboost import XGBClassifier
from sklearn.ensemble  import AdaBoostClassifier

# For scaling
# -------------------------------------------------------
from sklearn.preprocessing import StandardScaler

# * To convert categorical variables into numerical form
# --------------------------------------------------------
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import LabelEncoder

# *To balance the imbalanced data
# --------------------------------------------------------
from imblearn.over_sampling import RandomOverSampler

# * For spliting the dataset
# -------------------------------------------------------
from sklearn.model_selection import train_test_split

# *For computing the accuracy and  building a text report
# ------------------------------------------------------
from sklearn.metrics import classification_report,accuracy_score

# * Cross-validation
# ------------------------------------------------------
from sklearn.model_selection import RandomizedSearchCV

df.shape

df.isna().sum()

df.describe()

lst=[]
for i in df:
  if df[i].dtypes=='object':
    lst.append(i)

for i in lst:
  print(i, '|' ,(df[i].value_counts()))

lst1=lst[2:4]
lst1

dict1={}
for i in lst1:
  dict1[i]=LabelEncoder()
  df[i]=dict1[i].fit_transform(df[i])

df['Education'].unique()

df['City'].unique()

dict1

def one_column(df):
  lsts=[]
  for i in df:
    if df[i].dtypes=='object' and len(df[i].unique())>2:
      lsts.append(i)
  return lsts

one_column(df)

df.head()

df.dtypes

res=one_column(df)
res

onehot=OneHotEncoder(sparse_output=False,drop='first')
onehot_result=(onehot.fit_transform(df[['Education','City']]))
result=pd.DataFrame(onehot_result,columns=['0','1','2','3'])

df_new=df.join(result)

df_new.drop(columns=['Education','City'],inplace=True)

df_new.head()

import seaborn as sns
df.corr(numeric_only=True)
sns.heatmap(df_new.corr(numeric_only=True))

df.shape

import matplotlib.pyplot as plt
df_new.dtypes

df['LeaveOrNot'].value_counts()

x=df_new.drop(columns='LeaveOrNot')
y=df_new['LeaveOrNot']

over=RandomOverSampler()
x_over,y_over=over.fit_resample(x,y)
x_train,x_test,y_train,y_test=train_test_split(x_over,y_over,test_size=0.3,random_state=0)

ss=StandardScaler()
x_train_scaled=ss.fit_transform(x_train)
x_test_scaled=ss.transform(x_test)
knn=KNeighborsClassifier(n_neighbors=20,weights='distance')
knn.fit(x_train_scaled,y_train)

y_pred=knn.predict(x_test_scaled)

print(classification_report(y_test,y_pred))

print(accuracy_score(y_test,y_pred))

rs=RandomizedSearchCV(KNeighborsClassifier(),{'n_neighbors':[i for i in range(1,100)],'weights':['distance','uniform']},cv=10,n_iter=5)
x_scaled=ss.transform(x)
rs.fit(x_scaled,y)

rs.best_params_

rs.best_score_

model_svc=SVC()
model_svc.fit(x_train_scaled,y_train)

y_pred1=model_svc.predict(x_test_scaled)

print(classification_report(y_test,y_pred1))

print(accuracy_score(y_test,y_pred1))

print(accuracy_score(y_test,y_pred1))

rs1=RandomizedSearchCV(SVC(),{'C':[i for i in range(1,101)],'kernel':['poly','rbc','linear']},cv=10,n_iter=5)

rs1.fit(x,y)

rs1.best_score_

rs1.best_params_

berno=BernoulliNB()
berno.fit(x_train,y_train)

y_pred2=berno.predict(x_test)

len(x_test)

len(y_pred2)

print(classification_report(y_test,y_pred2))

print(accuracy_score(y_test,y_pred2))

dtc=DecisionTreeClassifier(criterion='entropy',max_depth=10)
dtc.fit(x_train,y_train)

y_pred3=dtc.predict(x_test)

print(classification_report(y_test,y_pred3))

print(accuracy_score(y_test,y_pred3))

rs2=RandomizedSearchCV(DecisionTreeClassifier(),{'criterion':['entropy','gini'],'max_depth':[10,20,50,100,500]},cv=10,n_iter=5)

rs2.fit(x,y)

rs2.best_params_

rs2.best_score_

rfc=RandomForestClassifier(n_estimators=50,criterion='entropy')
rfc.fit(x_train,y_train)

y_pred4=rfc.predict(x_test)

print(classification_report(y_test,y_pred4))

print(accuracy_score(y_test,y_pred4))

rs3=RandomizedSearchCV(RandomForestClassifier(),{'n_estimators':[i for i in range(1,500)],'criterion':['entropy','gini'],'min_samples_split':[10,20,50,100,1000]},cv=10,n_iter=5)

rs3.fit(x,y)

rs3.best_params_

rs3.best_score_

gbc=GradientBoostingClassifier(learning_rate=0.01,n_estimators=500,max_depth=10,min_samples_split=50)
gbc.fit(x_train,y_train)

y_pred5=gbc.predict(x_test)

print(classification_report(y_test,y_pred5))

print(accuracy_score(y_test,y_pred5))

rs4=RandomizedSearchCV(GradientBoostingClassifier(),{'learning_rate':[0.001,0.01,0.1,1,10,100],'n_estimators':[10,20,50,100,500],'max_depth':[i for i in range(1,50)],
                                                     'min_samples_split':[10,40,50,70,100,200]},cv=10,n_iter=5)


rs4.fit(x,y)

rs4.best_params_

rs4.best_score_

xgb=XGBClassifier(learning_rate=0.01,n_estimators=500,max_depth=10,min_samples_split=50)
xgb.fit(x_train,y_train)

y_pred6=xgb.predict(x_test)

print(classification_report(y_test,y_pred6))

print(accuracy_score(y_test,y_pred6))

rs5=RandomizedSearchCV(XGBClassifier(),{'learning_rate':[0.001,0.01,0.1,1,10,100],'n_estimators':[10,20,50,100,500],'max_depth':[i for i in range(1,50)]},cv=10,n_iter=5)

rs5.fit(x,y)

rs5.best_params_

rs5.best_score_

abc=AdaBoostClassifier(n_estimators=100,learning_rate=0.01)
abc.fit(x_train,y_train)

y_pred7=xgb.predict(x_test)

print(classification_report(y_test,y_pred7))

print(accuracy_score(y_test,y_pred))

rs6=RandomizedSearchCV(AdaBoostClassifier(),{'n_estimators':[i for i in range(1,250)],'learning_rate':[0.001,0.01,0.1,1,10,100]},cv=10,n_iter=5)

rs6.fit(x,y)

rs6.best_params_

rs6.best_score_

def predictions(Education, JoiningYear, City, PaymentTier, Age, Gender, EverBenched, ExperienceInCurrentDomain):
    # Preprocess input values
    Education_City_encoded = onehot.transform([[Education, City]])
    JoiningYear_encoded = np.array(JoiningYear).reshape(1,-1)
    PaymentTier_encoded = np.array(PaymentTier).reshape(1,-1)
    Age_encoded = np.array(Age).reshape(1,-1)
    Gender_encoded = np.array(dict1['Gender'].transform([Gender])[0]).reshape(1,-1)
    EverBenched_encoded = np.array(dict1['EverBenched'].transform([EverBenched])[0]).reshape(1,-1)
    ExperienceInCurrentDomain_encoded = np.array(ExperienceInCurrentDomain).reshape(1,-1)
    input_val=np.hstack((Education_City_encoded, JoiningYear_encoded, PaymentTier_encoded,
                             Age_encoded, Gender_encoded, EverBenched_encoded, ExperienceInCurrentDomain_encoded))
    test_df=pd.DataFrame(input_val,columns=x.columns)
    pred=abc.predict(test_df)
    return pred

prediction=predictions('Bachelors',2017,'Bangalore',3,34,'Male','No',0)
print(prediction)

